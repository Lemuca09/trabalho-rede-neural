# -*- coding: utf-8 -*-
"""PrevisaoAcoes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aPwEvSpty99XAXxz9JWHqAFNgz4Xksxf
"""

import os
import json
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

"""**ConfiguraÃ§Ãµes**"""

TICKERS = ['AAPL', 'MSFT', 'GOOGL']
# TICKERS = ['GOOGL']
# TICKERS = ['NVDA', 'AMZN', 'META', 'ODD'] # Exemplo onde ODD tende a ser contrÃ¡rio aos outros valores no PCA
# TICKERS = ['NVDA', 'AMZN', 'META']
WINDOW_SIZE = 12  # 12 semanas (~3 meses)
EPOCHS = 300 # 300
BATCH_SIZE = 4

TRAIN = False # Controle para se for necessÃ¡rio retreinar

FUTURE_STEPS = 4  # nÃºmero de semanas a prever

MODEL_PATH = "modelo_lstm_portfolio_acoes.h5"
HISTORY_PATH = "history_lstm.json"

"""**Baixar dados semanais dos Ãºltimos 3 anos**"""

dfs = []
for ticker in TICKERS:
    data = yf.Ticker(ticker).history(period="3y", interval="1wk")['Close']
    data.name = ticker
    dfs.append(data)

len(data), data

"""**Combinar e limpar**"""

df = pd.concat(dfs, axis=1)
df.dropna(inplace=True)

"""**Criar valor mÃ©dio do portfÃ³lio**"""

df['Portfolio'] = df.mean(axis=1)
portfolio_values = df['Portfolio'].values

"""**Padronizar (z-score)**"""

mean = np.mean(portfolio_values)
std = np.std(portfolio_values)
portfolio_scaled = (portfolio_values - mean) / std

mean, std, len(portfolio_scaled)

"""**Janela deslizante**"""

X, y = [], []
for i in range(len(portfolio_scaled) - WINDOW_SIZE): # ~145
    X.append(portfolio_scaled[i:i + WINDOW_SIZE])
    y.append(portfolio_scaled[i + WINDOW_SIZE])
X = np.array(X)
y = np.array(y)

len(X) # 158 Semanas - Window_Size=12, logo, 146

"""**Reshape para LSTM: (samples/batch_size, timesteps, features)**"""

X = X.reshape((X.shape[0], X.shape[1], 1)) # 102/44 sequÃªncias no batch, 12 Semanas, 1 Valor/PreÃ§o
X.shape

"""**Dividir treino/teste**"""

split = int(len(X) * 0.7) # 0.8
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

X[:split].shape, X[split:].shape      # 102/44 sequÃªncias, cada uma com 12 passos temporais, cada passo tem 1 feature.

"""**Dividir treino/teste** E **Treinar**"""

if os.path.exists(MODEL_PATH) and TRAIN != True:
    print("ðŸ” Carregando modelo salvo...")
    model = tf.keras.models.load_model(MODEL_PATH)
    model.compile(optimizer='adam', loss=tf.keras.losses.Huber(0.8), metrics=['mse','mae', 'mape'])
    with open(HISTORY_PATH, "r") as f:
        loss_data = json.load(f)
else:
    print("ðŸ” Treinando novo modelo...")
    model = tf.keras.Sequential([
        tf.keras.layers.LSTM(64, activation='tanh', input_shape=(WINDOW_SIZE, 1)),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(64, activation='elu'),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(1)
    ])

    model.compile(optimizer='adam', loss=tf.keras.losses.Huber(0.8), metrics=['mse','mae', 'mape'])
    history = model.fit(
        X_train, y_train,
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        validation_data=(X_test, y_test),
        verbose=1
    )
    model.save(MODEL_PATH)
    print(f"âœ… Modelo salvo em {MODEL_PATH}")

    # Salvar histÃ³rico - Loss
    with open(HISTORY_PATH, "w") as f:
        json.dump(history.history, f)
    print(f"âœ… HistÃ³rico salvo em {HISTORY_PATH}")

"""**Prever e Inverter PadronizaÃ§Ã£o**"""

predictions = model.predict(X_test).flatten() # Finalmente usa os Valores de Test para fazer as PrevisÃµes, passa todas as janelas de entrada (X) para o modelo LSTM e depois transforma um array 2D (shape: (n, 1)) para 1D
predictions_real = predictions * std + mean
y_test_real = y_test * std + mean


print(abs(history.history['val_loss'][-1]))
print(abs(history.history['val_mae'][-1]))
print(abs(history.history['val_mse'][-1]))
print(abs(history.history['val_mape'][-1]))
print()
print(abs(history.history['val_mape'][-1]- 100)) # Valor de Acerto em % do Modelo na Ãšltima Ã‰poca
print(abs(min(history.history['val_mape']) - 100)) # Valor de Acerto em % do Modelo na Ã‰poca com o valor de Erro mais Baixo. Onde o Peso e Bias estÃ¡ melhor ajustado.

"""## Visualizando o conjunto de teste (test set). O modelo foi treinado com 70% dos dados (split = int(len(X) * 0.7)), e o restante (30%) Ã© usado para teste e plot. Isso representa cerca de:

##156 semanas â‰ˆ **3 anos**

## 30% de 156 â‰ˆ 47 semanas, ou seja quase **12 meses**.
"""

dates = df.index[-len(y_test_real):]  # pega as datas correspondentes ao conjunto teste


plt.figure(figsize=(12, 5))
plt.style.use('dark_background')
plt.plot(dates, y_test_real, label='Valor real (MÃ©dia das AÃ§Ãµes)') if len(TICKERS) >= 2 else None
# for ticker in TICKERS:
#   plt.plot(dates, df[ticker][-len(y_test_real):].values, label=ticker) if len(TICKERS) > 1 else None
plt.plot(dates, predictions_real, label='PrevisÃ£o da rede', linestyle='--')
plt.title(f'PrevisÃ£o do PortfÃ³lio com Dados Mensais {len(dates)/4}')
plt.xlabel('Data')
plt.ylabel('Valor ($)')
plt.legend()
plt.grid(True)
plt.show()


dates[0], dates[-1]

print(f"{len(dates)} semanas de dados, logo {len(dates)/4} Meses") # Lembrar da SubtraÃ§Ã£o com Window Size

"""**SugestÃ£o de DecisÃ£o de Compra/Espera/Venda das AÃ§Ãµes**"""

threshold = 0.015  # 1.5% de variaÃ§Ã£o para decidir compra/venda

index_max = np.argmax(y_test_real)
index_min = np.argmin(y_test_real)

valor_max_real = y_test_real[index_max]
valor_max_previsto = predictions_real[index_max]
data_max = dates[index_max]

valor_min_real = y_test_real[index_min]
valor_min_previsto = predictions_real[index_min]
data_min = dates[index_min]

print(f"ðŸ“ˆ AÃ§Ã£o mais cara (PortfÃ³lio - {' e '.join(TICKERS)}):")
print(f"Data: {data_max.strftime('%Y-%m-%d')}")
print(f"Valor real   : ${valor_max_real:.2f}")
print(f"Valor previsto: ${valor_max_previsto:.2f}")
erro = valor_max_real - valor_max_previsto
print(f"Erro de: ${abs(erro):.2f}\n")

print(f"ðŸ“‰ AÃ§Ã£o mais barata (PortfÃ³lio - {' e '.join(TICKERS)}):")
print(f"Data: {data_min.strftime('%Y-%m-%d')}")
print(f"Valor real   : ${valor_min_real:.2f}")
print(f"Valor previsto: ${valor_min_previsto:.2f}")
erro2 = valor_min_real - valor_min_previsto
print(f"Erro de: ${abs(erro2):.2f}\n")

decisoes = []
for i in range(len(predictions_real) - 1):
    atual = predictions_real[i]
    futuro = predictions_real[i + 1]
    delta = (futuro - atual) / atual

    if i == 0:
        delta = 0
        decisao = "ðŸŸ¢ Compra"
    else:
        if delta > threshold:
            decisao = "ðŸŸ¢ Comprar"
        elif delta < -threshold:
            decisao = "ðŸ”´ Vender"
        else:
            decisao = "âšªï¸ Esperar"

    decisoes.append((dates[i].strftime('%Y-%m-%d'), atual, delta * 100, decisao))

print(f"ðŸ’° De Acordo com o modelo de PrevisÃ£o:\n")
print(f"{'Data':<12} {'Valor Atual':<14} {'Î”%':<8} {'DecisÃ£o'}")
for data, atual, delta, decisao in decisoes:
    print(f"{data:<12} ${atual:<13.2f} {delta:>+6.2f}%   {decisao}")

capital_inicial = 1000.0
dinheiro = capital_inicial
acoes = 0
historico_compras = []

for i, (data_str, atual, delta_pct, decisao) in enumerate(decisoes):
    delta = delta_pct / 100

    if i == 0 and dinheiro >= atual:
        maximo_acoes = int(dinheiro / atual)
        if maximo_acoes > 0:
            custo = maximo_acoes * atual
            dinheiro -= custo
            acoes += maximo_acoes
            historico_compras.append((data_str, maximo_acoes, atual))
        continue

    if decisao == "ðŸŸ¢ Comprar" and dinheiro >= atual:
        excesso = delta - threshold
        fator = excesso / threshold  # quanto acima do threshold
        fator = max(1.0, fator)  # no mÃ­nimo 1 aÃ§Ã£o

        fator = min((excesso / threshold), 5)  # fator de escala, limitado a 5
        orcamento = dinheiro * (fator / 5)  # usar parte proporcional do dinheiro
        maximo_acoes = int(orcamento / atual)  # limitar para evitar exageros

        if maximo_acoes > 0 and dinheiro >= maximo_acoes:
            custo = maximo_acoes * atual
            dinheiro -= custo
            acoes += maximo_acoes
            historico_compras.append((data_str, maximo_acoes, atual))

    elif decisao == "ðŸ”´ Vender" and acoes > 0:
        dinheiro += acoes * atual
        historico_compras.append((data_str, -acoes, atual))  # registro da venda
        acoes = 0

preco_final = predictions_real[-1]
valor_final = dinheiro + acoes * preco_final
lucro = valor_final - capital_inicial

if historico_compras:
    print("\nðŸ“‹ Registro de TransaÃ§Ãµes:")
    print(f"{'Data':<12} {'AÃ§Ãµes':<10} {'Valor UnitÃ¡rio':<15} {'Total'}")
    for data, qtd, valor in historico_compras:
        total = abs(qtd) * valor
        tipo = "Compra" if qtd > 0 else "Venda"
        print(f"{data:<12} {qtd:<10} ${valor:<14.2f} ${total:.2f} ({tipo})")
else:
    print("\nâš ï¸ Nenhuma transaÃ§Ã£o foi realizada.")

print("\nðŸ“Š Resultados finais da simulaÃ§Ã£o:")
print(f"Dinheiro restante (NÃ£o investido): ${dinheiro:.2f}")
print(f"AÃ§Ãµes restantes: {acoes}")
print(f"PreÃ§o final da aÃ§Ã£o: ${preco_final:.2f}")
print(f"Valor final da carteira: ${valor_final:.2f}")
print(f"Lucro total: ${lucro:.2f} - {(lucro/capital_inicial)*100:.2f}%")

"""**Passos Futuro**"""

last_window = portfolio_scaled[-WINDOW_SIZE:].tolist()
future_predictions_scaled = []

for _ in range(FUTURE_STEPS):
    input_array = np.array(last_window[-WINDOW_SIZE:]).reshape(1, WINDOW_SIZE, 1) # Como Ã© LSTM, redimensiona para o formato esperado
    next_pred = model.predict(input_array)[0, 0]
    future_predictions_scaled.append(next_pred)
    last_window.append(next_pred)

future_predictions_real = [p * std + mean for p in future_predictions_scaled] # Desnormaliza as previsÃµes para escala original

predictions_str = ', '.join([str(p) for p in future_predictions_real])
print(f"\nValores Previstos: {np.array(predictions_str)}")

plt.figure(figsize=(12, 5))
plt.style.use('dark_background')
plt.plot(df.index[-len(y_test_real):], y_test_real, label='Valor real (MÃ©dia das AÃ§Ãµes)')
plt.plot(df.index[-len(predictions_real):], predictions_real, label='PrevisÃ£o da rede', linestyle='--')
plt.plot(pd.date_range(df.index[-1], periods=FUTURE_STEPS+1, freq='W')[1:], future_predictions_real, label=f'PrevisÃ£o +{FUTURE_STEPS} semanas', linestyle='-.', color="red")
plt.title(f'PrevisÃ£o do PortfÃ³lio com ExtensÃ£o Futura (11 Meses + {FUTURE_STEPS} Semanas)')
plt.xlabel('Data')
plt.ylabel('Valor ($)')
plt.legend()
plt.grid(True)
plt.show()

"""####Esse grÃ¡fico mostra a performance do modelo LSTM ao longo dos **3 anos**, e nÃ£o sÃ³ no conjunto de teste."""

all_predictions = model.predict(X).flatten() # Passa todas as janelas de entrada (X) para o modelo LSTM e depois transforma um array 2D (shape: (n, 1)) para 1D
all_predictions_real = all_predictions * std + mean
all_y_real = y * std + mean

all_dates = df.index[WINDOW_SIZE:]  # compensar janela deslizante

plt.figure(figsize=(12, 6))
plt.style.use('dark_background')
plt.plot(all_dates, all_y_real, label='Valor real (MÃ©dia das AÃ§Ãµes)')
plt.plot(all_dates, all_predictions_real, label='PrevisÃ£o do modelo', linestyle='--')
plt.title('PrevisÃ£o do PortfÃ³lio nos Ãšltimos 3 Anos (Treino + Teste)')
plt.xlabel('Data')
plt.ylabel('Valor ($)')
plt.legend()
plt.grid(True)
plt.show()

len(all_dates)

"""**VisualizaÃ§Ã£o do Loss**"""

if history:
    loss_data = history.history
elif os.path.exists(HISTORY_PATH):
    with open(HISTORY_PATH, "r") as f:
        loss_data = json.load(f)
else:
    loss_data = None

if loss_data:
    plt.plot(loss_data['loss'], label='Training Loss')
    plt.plot(loss_data['val_loss'], label='Validation Loss')
    plt.title('Loss por Ã‰poca')
    plt.xlabel('Ã‰pocas')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.show()
else:
    print("âš ï¸ Nenhum histÃ³rico de loss encontrado.")

"""**Inicializar PCA**"""

scaler = StandardScaler()
if 'Portfolio' in df.columns:
  df = df.drop("Portfolio",axis=1)
scaled_df = scaler.fit_transform(df)

pca = PCA()
pca.fit(scaled_df)
explained_variance = pca.explained_variance_ratio_ # VariÃ¢ncia explicada por componente, quanto da variÃ¢ncia total cada componente principal explica

len(scaled_df), explained_variance,scaled_df, pca.components_, df

"""**Componentes principais (pesos das aÃ§Ãµes)**"""

components = pca.components_
pca_df = pd.DataFrame(components.T,
                      columns=[f'PC{i+1}' for i in range(len(components))],
                      index=df.columns)

"""**Mostrar a contribuiÃ§Ã£o de cada aÃ§Ã£o no 1Âª componente principal**"""

print("ContribuiÃ§Ã£o de cada aÃ§Ã£o no 1Âº componente principal (PC1):")
print(pca_df['PC1'].sort_values(ascending=False))

"""**Mostrar a contribuiÃ§Ã£o de cada aÃ§Ã£o no 2Âª componente principal**"""

if 'PC2' in pca_df.columns:
  print("ContribuiÃ§Ã£o de cada aÃ§Ã£o no 2Âº componente principal (PC2):")
  print(pca_df['PC2'].sort_values(ascending=False))

loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(len(df.columns))], index=df.columns)

def interpretar_pca(loadings):
    analises = []

    pc1_abs = loadings['PC1'].abs().sort_values(ascending=False)
    mais_influente = pc1_abs.index[0]
    menos_influente = pc1_abs.index[-1]

    analises.append(f"ðŸ’¡ AnÃ¡lise PC1\n\nâ© O componente principal 1 (PC1) representa a direÃ§Ã£o de maior variÃ¢ncia dos dados, ou seja, a combinaÃ§Ã£o linear que mais resume a variaÃ§Ã£o dos preÃ§os das aÃ§Ãµes.\n\nðŸ”€ {mais_influente} Ã© o ativo que mais influencia, enquanto {menos_influente} interfere menos.")

    if 'PC2' in loadings.columns:
        pc2 = loadings['PC2']
        positivos = pc2[pc2 > 0].sort_values(ascending=False)
        negativos = pc2[pc2 < 0].sort_values()

        if not positivos.empty and not negativos.empty:
            analises.append(
                f"\nðŸ’¡ AnÃ¡lise PC2\n\n"
                f"â© {positivos.index[0]} = {positivos.iloc[0]:.3f}: contribui positivamente para PC2.\n\n"
                f"â© {' e '.join(negativos.index)} negativos: vÃ£o na direÃ§Ã£o oposta de {positivos.index[0]} neste componente.\n\n"
                f"ðŸ” Isso sugere que quando {positivos.index[0]} se desvia da mÃ©dia geral, "
                f"{' e '.join(negativos.index)} tendem a ir na direÃ§Ã£o contrÃ¡ria."
            )

    return "\n\n".join(analises)

print(interpretar_pca(loadings))